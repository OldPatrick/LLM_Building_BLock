<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.10/dist/favicon.ico" />
    <!-- Preload is necessary because we show these images when we disconnect from the server,
    but at that point we cannot load these images from the server -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.10/dist/assets/gradient-yHQUC_QB.png" as="image" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.10/dist/assets/noise-60BoTA8O.png" as="image" />
    <!-- Preload the fonts -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.10/dist/assets/Lora-VariableFont_wght-B2ootaw-.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.10/dist/assets/PTSans-Regular-CxL0S8W7.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.10/dist/assets/PTSans-Bold-D9fedIX3.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.10/dist/assets/FiraMono-Regular-BTCkDNvf.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.10/dist/assets/FiraMono-Medium-DU3aDxX5.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.10/dist/assets/FiraMono-Bold-CLVRCuM9.ttf" as="font" crossorigin="anonymous" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta name="description" content="a marimo app" />
    <link rel="apple-touch-icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.10/dist/apple-touch-icon.png" />
    <link rel="manifest" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.10/dist/manifest.json" />

    <script data-marimo="true">
      function __resizeIframe(obj) {
        var scrollbarHeight = 20; // Max between windows, mac, and linux

        function setHeight() {
          var element = obj.contentWindow.document.documentElement;
          // If there is no vertical scrollbar, we don't need to resize the iframe
          if (element.scrollHeight === element.clientHeight) {
            return;
          }

          // Create a new height that includes the scrollbar height if it's visible
          var hasHorizontalScrollbar = element.scrollWidth > element.clientWidth;
          var newHeight = element.scrollHeight + (hasHorizontalScrollbar ? scrollbarHeight : 0);

          // Only update the height if it's different from the current height
          if (obj.style.height !== `${newHeight}px`) {
            obj.style.height = `${newHeight}px`;
          }
        }

        // Resize the iframe to the height of the content and bottom scrollbar height
        setHeight();

        // Resize the iframe when the content changes
        const resizeObserver = new ResizeObserver((entries) => {
          setHeight();
        });
        resizeObserver.observe(obj.contentWindow.document.body);
      }
    </script>
    <marimo-filename hidden>05_async_llm_spam_detection_w_cache.py</marimo-filename>
    <!-- TODO(Trevor): Legacy, required by VS Code plugin. Remove when plugin is updated (see marimo/server/_templates/template.py) -->
    <marimo-version data-version="{{ version }}" hidden></marimo-version>
    <marimo-user-config data-config="{{ user_config }}" hidden></marimo-user-config>
    <marimo-server-token data-token="{{ server_token }}" hidden></marimo-server-token>
    <!-- /TODO -->
    <title>05 async llm spam detection w cache</title>
    <script type="module" crossorigin crossorigin="anonymous" src="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.10/dist/assets/index-txb0mb7R.js"></script>
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.10/dist/assets/index-B-hr6ABS.css">
  
<script data-marimo="true">
    window.__MARIMO_STATIC__ = {};
    window.__MARIMO_STATIC__.files = {};
</script>
</head>
  <body>
    <div id="root"></div>
    <script data-marimo="true">
      window.__MARIMO_MOUNT_CONFIG__ = {
            "filename": "05_async_llm_spam_detection_w_cache.py",
            "mode": "read",
            "version": "0.14.10",
            "serverToken": "static",
            "config": {"completion": {"activate_on_typing": true, "copilot": false}, "display": {"cell_output": "above", "code_editor_font_size": 14, "dataframes": "rich", "default_table_page_size": 10, "default_width": "medium", "reference_highlighting": false, "theme": "light"}, "formatting": {"line_length": 79}, "keymap": {"overrides": {}, "preset": "default"}, "language_servers": {"pylsp": {"enable_flake8": false, "enable_mypy": true, "enable_pydocstyle": false, "enable_pyflakes": false, "enable_pylint": false, "enable_ruff": true, "enabled": true}}, "package_management": {"manager": "uv"}, "runtime": {"auto_instantiate": true, "auto_reload": "off", "default_sql_output": "auto", "on_cell_change": "autorun", "output_max_bytes": 8000000, "reactive_tests": true, "std_stream_max_bytes": 1000000, "watcher_on_save": "lazy"}, "save": {"autosave": "after_delay", "autosave_delay": 1000, "format_on_save": false}, "server": {"browser": "default", "follow_symlink": false}, "snippets": {"custom_paths": [], "include_default_snippets": true}},
            "configOverrides": {},
            "appConfig": {"sql_output": "auto", "width": "medium"},
            "view": {"showAppCode": true},
            "notebook": {"cells": [{"code": "mo.md(\n    r\"\"\"\n<Strong>Cache Does Not Preserve Order of Insertion</strong>\n\nOne important thing to understand about the diskcache (and many other cache implementations) is that it is a key-value store, not a data structure that preserves the order of insertion or retrieval. When you iterate over the cache using methods like keys(), iterkeys(), or view().iterkeys(), the order of the keys returned is not necessarily the order in which they were inserted. The cache is essentially a hash-based structure, and the order of keys is typically not guaranteed.\n\"\"\"\n)", "code_hash": "68cbc7c29c65aaa92cdf4e42666e8ed9", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hbol", "name": "_"}, {"code": "import asyncio\nimport llm\nimport marimo as mo\nimport polars as pl\nimport matplotlib.pyplot as plt\n\nfrom dotenv import load_dotenv\nfrom datasets import load_dataset\nfrom mosync import async_map_with_retry\nfrom diskcache import Cache\nfrom sklearn.metrics import confusion_matrix, precision_score\nload_dotenv(\".env\")", "code_hash": "552bea1f89a231e307278193062e9bf7", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "MJUe", "name": "_"}, {"code": "# Show Async-Ready Models\nfor model in llm.get_async_models():\n    print(model.model_id)", "code_hash": "06f43accdd1fee3642480bb7d50ac992", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "vblA", "name": "_"}, {"code": "# Huggingface dataset about spam: \n# https://huggingface.co/datasets/Deysi/spam-detection-dataset\ndf = load_dataset(\"Deysi/spam-detection-dataset\")", "code_hash": "c277a586d64e6712a18b119c0b1d6723", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "bkHC", "name": "_"}, {"code": "df_train = df[\"train\"].to_polars()\ndf_test = df[\"test\"].to_polars()", "code_hash": "5c9b45010c6bf46d9d738088647f2010", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "lEQa", "name": "_"}, {"code": "cache = Cache(\"LLM_Prompt_Cache\")\n\nmodels = {\n    \"gpt-4\": llm.get_async_model(\"gpt-4\"),\n    \"gpt-4o\": llm.get_async_model(\"gpt-4o\"),\n    \"sonnet2024\": llm.get_async_model(\"anthropic/claude-3-5-sonnet-20241022\"),\n    \"haiku\": llm.get_async_model(\"anthropic/claude-3-haiku-20240307\")\n\n}", "code_hash": "3d9901b4c02a51cf5b2a5e36ca9147fa", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "PKri", "name": "_"}, {"code": "prompt = \"is this spam or ham? only reply with spam or ham\"\nbase_llm = \"sonnet2024\"", "code_hash": "76411bb3cd8ca1a51c7af86e6328cdf0", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Xref", "name": "_"}, {"code": "async def classify(text, prompt=prompt, model=base_llm):\n    tup = (text, prompt, model)\n    if tup in cache:\n        #check if cached result is found\n        print(tup in cache)\n        return cache[tup]\n    resp = await models[model].prompt(prompt + \"\\n\" + text).json()\n    cache[tup] = resp\n    return resp", "code_hash": "3e75178ba74212dce0c85c3cf188e710", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "SFPL", "name": "_"}, {"code": "await classify(\"hello there\")", "code_hash": "c24abdc31e272cbf71aacf4ef57e6c04", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "BYtC", "name": "_"}, {"code": "n_eval = 50\n\nllm_results = await async_map_with_retry(\n    [_[\"text\"] for _ in df_test.head(n_eval).to_dicts()], \n    classify, \n    max_concurrency=3, \n    description=\"Running LLM experiments\"\n)\n\nllm_results_list = []\nprint(len(llm_results_list))", "code_hash": "6e639c19a21bb8ee11a802e270d5ecc6", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "RGSE", "name": "_"}, {"code": "#store the prompt as key, to be sure, that you have a contant match between predictions from cache and real labels\nfor k, result in enumerate(llm_results):\n    llm_results_list.append((result.item, result.result[\"content\"][0][\"text\"]))\n\nprint(len(llm_results_list))\nllm_results_list", "code_hash": "d0aa04a88b2e4f3a5d97047b8d2fea42", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Kclp", "name": "_"}, {"code": "df_test_labels = (\n    df_test.head(50).with_columns(\n        trues = pl.when(pl.col(\"label\").eq(\"not_spam\")).then(pl.lit(\"ham\")).otherwise(pl.lit(\"spam\"))\n    ).select(\"text\", \"trues\")\n)\n\nllm_frame = pl.DataFrame(llm_results_list, schema=[\"text\", \"label_llm\"], orient=\"row\")\n\ndf_equal = (\n    llm_frame\n        .join(df_test_labels, on=\"text\")\n        .with_columns(\n           trues = pl.when(pl.col(\"trues\").eq(\"ham\")).then(1).otherwise(0),\n           label_llm = pl.when(pl.col(\"label_llm\").eq(\"ham\")).then(1).otherwise(0)\n        )\n)", "code_hash": "bfb7172620adc604a521717b089ed8c5", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hstk", "name": "_"}, {"code": "cm = confusion_matrix(y_true=df_equal[\"trues\"], y_pred=df_equal[\"label_llm\"])\ncm", "code_hash": "b2bd59bc23db164c2c820e8e6cd9e7ae", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "nWHF", "name": "_"}, {"code": "print(\"model: \", base_llm, \"prompt: \", prompt, \"Precision:\", precision_score(df_equal[\"trues\"], df_equal[\"label_llm\"], average='weighted'), \"%\")", "code_hash": "2f9313d73c66ec2d12ae37ef922317e3", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "TukZ", "name": "_"}, {"code": "print(\"model: \", base_llm, \"prompt: \", prompt, \"Precision:\", precision_score(df_equal[\"trues\"], df_equal[\"label_llm\"], average='weighted'), \"%\")", "code_hash": "2f9313d73c66ec2d12ae37ef922317e3", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ZHCJ", "name": "_"}, {"code": "cache.peekitem()", "code_hash": "2a34dbd4b951ae7913d266c08dd1ef78", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "TqIu", "name": "_"}, {"code": "#import numpy as np\n#from sklearn.pipeline import make_pipeline\n#from sklearn.linear_model import LogisticRegression\n#from sklearn.feature_extraction.text import CountVectorizer\n#\n#df_valid, df_train = df.head(200), df.tail(200)\n#text_valid = df_valid[\"text\"].to_list()\n#text_train = df_train[\"text\"].to_list()\n#y_valid = df_valid[\"label\"].to_list()\n#y_train = df_train[\"label\"].to_list()\n#\n#pipe = make_pipeline(CountVectorizer(), LogisticRegression())\n#\n## It's pretty dang accurate\n#preds = pipe.fit(text_train, y_train).predict(text_valid)\n#np.mean(preds == np.array(y_valid))", "code_hash": "5ac70cdb02d29c5dd0d2c492a3f3c6be", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "DnEU", "name": "_"}], "metadata": {"marimo_version": "0.14.10"}, "version": "1"},
            "session": {"cells": [{"code_hash": "68cbc7c29c65aaa92cdf4e42666e8ed9", "console": [], "id": "Hbol", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><span class=\"paragraph\"><Strong>Cache Does Not Preserve Order of Insertion</strong></span>\n<span class=\"paragraph\">One important thing to understand about the diskcache (and many other cache implementations) is that it is a key-value store, not a data structure that preserves the order of insertion or retrieval. When you iterate over the cache using methods like keys(), iterkeys(), or view().iterkeys(), the order of the keys returned is not necessarily the order in which they were inserted. The cache is essentially a hash-based structure, and the order of keys is typically not guaranteed.</span></span>"}, "type": "data"}]}, {"code_hash": "552bea1f89a231e307278193062e9bf7", "console": [], "id": "MJUe", "outputs": [{"data": {"text/html": "<pre style='font-size: 12px'>True</pre>"}, "type": "data"}]}, {"code_hash": "06f43accdd1fee3642480bb7d50ac992", "console": [{"name": "stdout", "text": "gpt-4o\nchatgpt-4o-latest\ngpt-4o-mini\ngpt-4o-audio-preview\ngpt-4o-audio-preview-2024-12-17\ngpt-4o-audio-preview-2024-10-01\ngpt-4o-mini-audio-preview\ngpt-4o-mini-audio-preview-2024-12-17\ngpt-4.1\ngpt-4.1-mini\ngpt-4.1-nano\ngpt-3.5-turbo\ngpt-3.5-turbo-16k\ngpt-4\ngpt-4-32k\ngpt-4-1106-preview\ngpt-4-0125-preview\ngpt-4-turbo-2024-04-09\ngpt-4-turbo\ngpt-4.5-preview-2025-02-27\ngpt-4.5-preview\no1\no1-2024-12-17\no1-preview\no1-mini\no3-mini\no3\no4-mini\nanthropic/claude-3-opus-20240229\nanthropic/claude-3-opus-latest\nanthropic/claude-3-sonnet-20240229\nanthropic/claude-3-haiku-20240307\nanthropic/claude-3-5-sonnet-20240620\nanthropic/claude-3-5-sonnet-20241022\nanthropic/claude-3-5-sonnet-latest\nanthropic/claude-3-5-haiku-latest\nanthropic/claude-3-7-sonnet-20250219\nanthropic/claude-3-7-sonnet-latest\nanthropic/claude-opus-4-0\nanthropic/claude-sonnet-4-0\n", "type": "stream"}], "id": "vblA", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "c277a586d64e6712a18b119c0b1d6723", "console": [], "id": "bkHC", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "5c9b45010c6bf46d9d738088647f2010", "console": [], "id": "lEQa", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "3d9901b4c02a51cf5b2a5e36ca9147fa", "console": [], "id": "PKri", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "76411bb3cd8ca1a51c7af86e6328cdf0", "console": [], "id": "Xref", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "3e75178ba74212dce0c85c3cf188e710", "console": [], "id": "SFPL", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "c24abdc31e272cbf71aacf4ef57e6c04", "console": [], "id": "BYtC", "outputs": [{"data": {"application/json": "{\"id\": \"msg_01LyyBbKz3nSAD76Ea7kUvDs\", \"content\": [{\"citations\": null, \"text\": \"ham\", \"type\": \"text\"}], \"model\": \"claude-3-haiku-20240307\", \"role\": \"assistant\", \"stop_reason\": \"end_turn\", \"stop_sequence\": null, \"type\": \"message\"}"}, "type": "data"}]}, {"code_hash": "6e639c19a21bb8ee11a802e270d5ecc6", "console": [{"name": "stdout", "text": "True\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\n", "type": "stream"}, {"name": "stdout", "text": "True\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\n0\n", "type": "stream"}], "id": "RGSE", "outputs": [{"data": {"text/html": "<div style='display: flex;flex: 1;flex-direction: column;justify-content: flex-start;align-items: normal;flex-wrap: nowrap;gap: 0.5rem'><marimo-progress data-title='&quot;Running LLM experiments&quot;' data-total='50' data-progress='50' data-rate='2940.85' data-eta='0.0'></marimo-progress></div>"}, "type": "data"}]}, {"code_hash": "d0aa04a88b2e4f3a5d97047b8d2fea42", "console": [{"name": "stdout", "text": "50\n", "type": "stream"}], "id": "Kclp", "outputs": [{"data": {"application/json": "[[\"Check out these AMAZING weight loss pills that will make you lose 30 pounds in one week!!! \\ud83d\\udc8a\\ud83d\\udcaa\\ud83c\\udffd\\ud83d\\udc4c\\ud83c\\udffc Don't waste your time with exercise and healthy eating, just pop a pill and watch the fat melt away! \\ud83d\\udd25\\ud83d\\ude31 Limited time offer, buy now!! \\ud83d\\ude4c\\ud83c\\udffc #weightlosstips #healthyliving #fitfam #fitnessjourney #summerbodygoals\\n\\n\", \"spam\"], [\"I need to brush up my probability and algebra concepts for my upcoming machine learning classes. Any apps/ flash card type lessons would be awesome\", \"ham\"], [\"Are you tired of your boring old life? Well, we've got news for you! Our social network is the answer to all your problems! Join us now and be a part of something truly amazing! Our platform is the perfect place for you to express yourself and meet people from all walks of life.\\n\\n\", \"spam\"], [\"[Kaggle link](https://www.kaggle.com/colinmorris/favicons)\\n\\nI scraped these about a year ago, with the intention of training some generative neural networks on them. I never ended up finishing that project, but I thought other people might have some use for the data.\\n\\nI made a little [notebook](https://www.kaggle.com/colinmorris/unusual-favicons-a-brief-survey) that shows some examples from the dataset, with an emphasis on exploring examples that are unusual in various ways.\\n\\nBecause they're naturally tiny images, (16x16 is the most common size), my hope is that they might be useful as an MNIST-like dataset that can be used to play with deep learning models without prohibitive hardware/time requirements.\", \"ham\"], [\"Get rich quick with this amazing investment opportunity! Don't miss out on the chance to make BIG money fast! Just sign up and deposit your cash \\u2013 we guarantee huge profits!\\n\\n\", \"spam\"], [\"For eg, can i use the Titanic dataset? Really confused - since i wont be reproducing or distributing the data.\", \"ham\"], [\"Hi, I'm looking for vehicle crash data captured from accelerometers or similar instruments. I'd imagine most commonly would be taken from phones. Thanks.\", \"ham\"], [\"I've been trying to find some sort of web-based feed for the national debt.  It seems that most sites simply calculate the number and don't consume any sort of up-to-date feed. Thanks in advance to anybody who can help a brotha out.\", \"ham\"], [\"Get ready to be blown away by the most amazing offers and discounts on our platform! We've got it all, from cosmetics to electronics, and everything in between. Our deals are hotter than a summer day in the desert, so don't miss out!\\n\\n\", \"spam\"], [\"Looking for a big list of units of measurement. At the minimum I would like a unit and its conversion factor to SI units like this:\\n\\n| Unit | SI | Conversion Factor |\\n|------|-------|-------------------|\\n| in | meter | 0.0254 |\\n\\nThe more info on the unit the better things like name, unit, type of unit would all be extra helpful. https://www.nist.gov seems to have tons of data on this subject but I couldn't find an actual long list with units and conversion factors.\\n\\nThanks in advance.\", \"ham\"], [\"CHECK OUT THESE AMAZING DEALS!! 50% OFF EVERYTHING!! \\nDon't miss out on this incredible opportunity to SAVE! Get the hottest new products at half the price! \\nLimited time offer! Don't wait, SHOP NOW! \\n\\n\", \"spam\"], [\"Are you tired of being lame and boring? Do you want to stand out and be the coolest kid on the block? Then you need to join our social network community now! We've got all the latest trends and memes, and our platform is the perfect way to show off your unique style and personality.\\n\\n\", \"spam\"], [\"I want to do a Datascience project on failed retail store locations. My idea is to get a list of all active retail store locations for a specific, large chain (e.g. Starbuck, Marks &amp; Spencer, etc') and a list of all of their historical locations (all stores they ever opened), then mark the difference as \\\"closed\\\"/failed stores. Even better would be some dataset with store level performance (i.e annual sales) but I can't find that. I need real world location (latLong is best), so anonymized data like Kaggle's Rossman store sales doesn't cut it. \\n\\nAny advice? I found datasets for all existing store locations (for, e.g. Starbucks), but nothing about historical locations (scraping wouldn't help for that. Ideally i'd love an existing dataset, not scraping). \", \"ham\"], [\"Hey guys,\\n\\nI have a problem that probaly one of you can help me with. I am using IBM SPSS 24 and got a dataset which I am using for my research internship. Okay so i have a dependent variable called underweight that is dichotomous (Yes/No), however i want to transform this into a continous variable (percentage 0-100). The dataset is from a Survey of Households and each case is a member under 5 years old of the household for this variable. I ultimately want to see wheter the differences in underweight between clusters, region and climatic zones in the country I'm doing my research on (Benin) significantly differs. Now I can ofcourse use crosstabs and examine the % per climatic zones (3), regions (12) and clusters (448) however i want to use them in a T-test so i need to have them as a variable. Does anybody know a trick how to get this done? thank you in advance!\", \"ham\"], [\"Are you tired of being lonely? Do you desperately crave attention and validation from strangers on the internet? Look no further, because (insert social network name here) has got you covered!\\n\\nOur platform is the perfect place to post your every thought and feeling, no matter how trivial or mundane. Share every meal, every outfit, every haircut, and watch the likes roll in. And don't worry, we won't judge you for being basic or unoriginal - in fact, we encourage it!\\n\\nBut wait, there's more! Our algorithm is specifically designed to keep you addicted and scrolling for hours on end. We'll bombard you with targeted\", \"spam\"], [\"I have a project where I have to input a data set into Tableau and examine it. I\\u2019m struggling to find a good dataset that isn\\u2019t too large. I\\u2019m mostly interested in something simple like finding out top tv series and ratings but haven\\u2019t found one with enough data for that! \\n\\nCan someone recommend me some easy datasets to go through? Thank you so much\", \"ham\"], [\"I don't need all the years, but the farther it goes back the better.\", \"ham\"], [\"I'd appreciate a list of autonomous car driving deaths. In which the autonomous mode was operating.  \\nAlso, how can a person estimate the ratio between autonomous drive hours and non-autonomous ones?\\n\\nThanks a lot.\", \"ham\"], [\"FREE MONEY $$$$ 10,000$ FOR YOU!!! YES, IT'S TRUE! JUST CLICK HERE AND ENTER YOUR BANK ACCOUNT INFORMATION FOR IMMEDIATE DEPOSIT!!!!!\\n\\n\", \"spam\"], [\"Get ready to BOOST YOUR FOLLOWERS and make money on INSTAGRAM! With our exclusive program, you can increase your followers by 10k in just 24 hours! That's right, TEN THOUSAND followers in ONE DAY!\\n\\n\", \"spam\"], [\"Get rich quick! Join our amazing money-making scheme now! Just send us $100 and we'll guarantee you'll make a million in a month. Don't miss out on this incredible opportunity.\\n\\n\", \"spam\"], [\" Deezer.com 10,406,168 Artist DB\\n\\nWe have scraped the Deezer Artist DB, right now there are 10,406,168 listings according to Deezer.com\\n\\nPlease note in going through part of the list, it is obvious there are mistakes inside their system.\\n\\nExamples include and Artist with &amp; in its name might also be found with \\\"and\\\" but the Albums for each have different totals etc. Have no clue if there are duplicate albums etc do this error in their system. Even a comma in a name could mean the Artist shows up more than once, I saw in 1 instance that 1 Artist had 6 different ArtistIDs due to spelling errors.\\n\\nSo what is this DB, very simple, it gives you the ArtistID and the actual name of the Artist in another column. If you want to see the artist you add the baseurl to the ArtistID\\n\\nAn example is ArtistID 115 is AC/DC\\n\\n[https://www.deezer.com/us/artist/115](https://www.deezer.com/us/artist/115)\\n\\nYou do not have to use [https://www.deezer.com/us/artist/](https://www.deezer.com/us/artist/) if your first language is other than English, just see if Deezer supports your language and use that baseref\\n\\nFrench for example is [https://www.deezer.com/fr/artist/115](https://www.deezer.com/fr/artist/115)\\n\\nI am providing the DB in 3 different formats:\\n\\n \\n\\nI tried posting download links here but it seems Reddit does not like that so get them here:\\n\\n[https://pastebin\\\\[DOT\\\\]com/V3KJbgif](https://pastebin.com/V3KJbgif)\\n\\n&amp;#x200B;\\n\\n**Special thanks go to** [**/user/KoalaBear84**](https://www.reddit.com/user/KoalaBear84) **for writing the scraper.**\\n\\n&amp;#x200B;\\n\\n**Cross Posted to related Reddit Groups**\", \"ham\"], [\"Historical data of each FIFA affiliated country (at that time) and their rankings\", \"ham\"], [\"Buy our amazing product now and you'll never want anything else again! It's gonna make your life better in every possible way! Plus, get a FREE bonus offer when you order within the next 5 minutes!\\n\\n\", \"spam\"], [\"I've searched for straight three hours now, but how can I use this dataset, because it's content is a file with no ending.\\nI can't seem to find anything how to load that into Pytorch.\\nAny help would be greatly appreciated, because I seem too stupid to figure it out!\\n\\nDatset: https://commonvoice.mozilla.org/\", \"ham\"], [\"ATTENTION ALL USERS!!! Want to make fast cash? Follow these simple steps and become a millionaire overnight!!! \\ud83d\\udcb0\\ud83d\\udcb0\\ud83d\\udcb0\\n\\nStep 1: Click the link in my bio and sign up for our exclusive wealth-building program! \\ud83e\\udd11\\ud83e\\udd11\\ud83e\\udd11\\n\\nStep 2: Share this post with your friends and family to spread the word about this amazing opportunity!!! \\ud83d\\udde3\\ufe0f\\ud83d\\udde3\\ufe0f\\ud83d\\udde3\\ufe0f\\n\\nStep 3: Sit back and watch the money roll in!!! \\ud83d\\udcb8\\ud83d\\udcb8\\ud83d\\udcb8\\n\\nDon't miss out on this once-in-a-lifetime chance to live a life\", \"spam\"], [\"\\\"OMG! Check out these amazing weight loss pills that really work!!! Lose 50 pounds in just ONE WEEK!!! Limited time offer, BUY NOW!!!\\\"\\n\\n\", \"spam\"], [\"I'm working on a stats project to test some of the skills we've learned in class on a real dataset. However all the datasets I'm finding, while interesting, don't meet the assumptions of any models I've learnt to use. The ones I've found require more knowledge than I have to analyse (stuff like very skewed, very zero inflated continuous data). I'm looking for a biological/ ecological dataset with a normally distributed response variable that I can model with a linear model or linear mixed model, or some basic GLM like poisson or binomial in R so I can get to practice some of the techniques I've learned. Can anyone give me any suggestions on where to look, or even what sort of data might be relatively simple to work with?\", \"ham\"], [\"Im looking to get a hold of a data set that has come from a GPS unit worn by a player or several players during a sports game of soccer/football, rugby, netball, basketball, rugby league, or basically any sport really\", \"ham\"], [\"Hey guys, just looking for any datasets from pro cyclists that includes watts.\", \"ham\"], [\"Greetings, my fellow social media enthusiasts! I'm here to present to you the most amazing offer that will blow your mind! Do you want to gain thousands of followers overnight? Are you tired of having a boring timeline with no engagement? Look no further, because we have the solution for you!\\n\\nOur premium package offers you a chance to buy followers, likes and comments at an affordable price! No more sweating for hours on end, trying to create amazing content for your social media \\u2013 now you can sit back and relax while our bots do the work for you!\\n\\nBut wait, there's more! Our state-of-the-art software can also increase\", \"spam\"], [\"Are you tired of being uncool and unpopular? Do you want to be part of the cool crowd? Then look no further, because [Insert social network here] is the solution to all your problems! \\n\\nOur platform offers everything you need to impress your friends and be the talk of the town. With our extensive list of filters, your selfies will be so enhanced that even Beyonc\\u00e9 will be jealous. Plus, our algorithm guarantees that your posts will always get the most likes and comments, making you the star of the show.\\n\\nBut wait, there's more! By using [Insert social network here], you'll have access to exclusive content\", \"spam\"], [\"Hey guys and gals, are you tired of being lame and not having any friends? Well, you're in luck, because our social network is here to save the day! We've got all the features you could want in a platform, like photos and videos and status updates and likes and comments and shares and anything else you can think of! Plus, we've got tons of hot singles in your area who are just itching to meet someone like you. And don't worry, our site is totally secure and definitely won't steal all your personal information and sell it to the highest bidder. So what are you waiting for? Sign up\", \"spam\"], [\"L@@k at these Unbelievable diet pills that can melt away up to 50 pounds in 3 days! Get yours now! Don't miss out on this LIMITED-TIME offer!\\n\\n\", \"spam\"], [\"Attention all netizens! It's time to get pumped and stoked for this epic announcement brought to you by the one and only, (insert social network name). Are you ready to elevate your online presence to greater heights? Of course, you are! So, without further ado, let's dive right in.\\n\\nFirst things first, have you been feeling like your feed lacks a bit of spice lately? Well, worry no more! Our latest update is fresh off the press, and it's juicier than a ripe watermelon. Get ready to be hit with an avalanche of likes, comments, and DMs. We're talking\", \"ham\"], [\"Check out these amazing weight loss pills that will help you shed those extra pounds in just a few days! \\n\\n\", \"spam\"], [\"YOLO peeps! Are you ready to level up your social media game? Here at [insert social network name], we bring you the ultimate platform for all your #goals and #hustle. \\n\\nWith our new and improved filters, you can now enhance your posts and make them pop like never before. And don't forget to use our trending hashtags to gain more followers and likes. #InstaFamous #SlayQueen #Blessed \\n\\nBut wait, there's more! Our algorithm ensures that your posts reach a wider audience, and our sponsored ads can give your brand the boost it needs. So why settle for\", \"spam\"], [\"\\ud83d\\udea8 ATTENTION ALL USERS! \\ud83d\\udea8\\n\\n\\ud83c\\udd98 Are you looking for a way to GET RICH QUICK? \\ud83c\\udd98\\n\\n\\ud83d\\udcb0 Don't waste your time with boring old jobs! \\ud83d\\udcb0\\n\\n\\ud83d\\udcb8 Join our CRAZY MONEY-MAKING SYSTEM today! \\ud83d\\udcb8\\n\\n\\ud83e\\udd11 Just sign up and start earning BIG BUCKS right away! \\ud83e\\udd11\\n\\n\\ud83d\\udc49 Plus, if you refer your friends, you'll get even MORE CASH! \\ud83d\\udc48\\n\\n\\ud83d\\udd25 This is the HOTTEST OFFER of the year! \\ud83d\\udd25\\n\\n\\ud83d\\udc4d Don't wait\", \"spam\"], [\"HOT SINGLES IN YOUR AREA! FIND THEM NOW!\\n\\n\", \"spam\"], [\"Hi -- I am trying to get a handle on public data across the country at the county-level.  Basically, I want to know what types of info are out there generally (demographic / economic / etc.) and, ideally, who is aggregating this at the state (or national?) level.  Can anyone advise on where to start with this?\\n\\nEDIT: I neglected to specify that I mean for the US.\", \"ham\"], [\"Upd8 Your W3b Pr0fil3! Click h3re!\\n\\nHeyyyy evrybudy!! Wazzup?? R U bored with yr boring social netwurk profile?? Well, I hav the solut1on!! Check out th1s amazinggg new websyte that wil upd8 yr web profil3 in no tim3! U'll get mor lik3s and follow3rs than evur befor! Ju$t click th3 link and y0u'll b3 tak3n to a whol3 n3w world of awesumness! And thats not all, wt\", \"spam\"], [\"Hey people, I hope someone could help me with this! \\n\\nLooking for big datasets of registered websites per country and/or regions (Europe, North America, Asia, etc.). Already searched on the internet (tbh looking for that for a couple of days without any serious results). \\n\\nIs there any resource I can use to do some analysis?\\n\\nThanks in advance!\", \"ham\"], [\"Are you tired of being single and not having any likes on your photos? Well, fear not because our site is here to save the day! \\n\\n\", \"spam\"], [\"What the title says =)\\nThanks.\", \"ham\"], [\"Not looking for specific dataset of a country. any dataset related to any country is appreciated.  \\nThank you in advance\", \"ham\"], [\"Itz time to gear up for a whoppin' good time on our site! We've got all the latest and greatest memes, videos, and pics to keep you entertained for hours. Plus, we've got deals galore on products you never knew you needed! Trust us, you won't be able to resist our tempting offers.\\n\\nAnd don't forget about our amazing community of followers. They're always sharing their wildest stories and craziest adventures. So why not join the fun and become a part of our online fam? We guarantee you won't regret it.\\n\\nBut wait, there's more! We've also got\", \"spam\"], [\"The states could represent any domain and different data formats are ok as well. https://transitionmatrix.readthedocs.io/en/latest/\", \"ham\"], [\"GET RIIIIICH QUICK!!! \\ud83d\\udcb0\\ud83d\\udcb0\\ud83d\\udcb0 \\n\\ud83d\\ude80\\ud83d\\ude80\\ud83d\\ude80\\nJoin our AMAZIIIIING network of money makers! \\ud83e\\udd11\\ud83e\\udd11\\ud83e\\udd11 \\n\\ud83d\\udc49\\ud83d\\udc49\\ud83d\\udc49\\nNo more 9-5 grind, just sit back and watch the CASH ROLL IN \\ud83e\\udd11\\ud83e\\udd11\\ud83e\\udd11\\ud83d\\udcb5\\ud83d\\udcb5\\ud83d\\udcb5\\n\\ud83d\\ude4c\\ud83d\\ude4c\\ud83d\\ude4c\\nDon't wait, sign up NOW and make your dreams come true!! \\ud83d\\udcb8\\ud83d\\udcb8\\ud83d\\udcb8\\n\\n\", \"spam\"], [\"[[Sorry, I cannot generate inappropriate or spam content. Please provide a different prompt.]]\", \"ham\"], [\"\\\"Get ready for the biggest discount of your life! Our product will change your life forever! Don't miss this limited time offer, only for our loyal followers! But wait, there's more! Sign up now and receive a free gift with your purchase. You won't regret it, we guarantee it!\\n\\n\", \"spam\"]]"}, "type": "data"}]}, {"code_hash": "bfb7172620adc604a521717b089ed8c5", "console": [], "id": "Hstk", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "b2bd59bc23db164c2c820e8e6cd9e7ae", "console": [], "id": "nWHF", "outputs": [{"data": {"text/html": "<pre style='font-size: 12px'>array([[26,  2],\n       [ 0, 22]])</pre>"}, "type": "data"}]}, {"code_hash": "2f9313d73c66ec2d12ae37ef922317e3", "console": [{"name": "stdout", "text": "model:  sonnet2024 prompt:  is this spam or ham? only reply with spam or ham Precision: 0.9633333333333333 %\n", "type": "stream"}], "id": "TukZ", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "2f9313d73c66ec2d12ae37ef922317e3", "console": [{"name": "stdout", "text": "model:  haiku prompt:  is this spam or ham? only reply with spam or ham Precision: 0.9808695652173912 %\n", "type": "stream"}], "id": "ZHCJ", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "2a34dbd4b951ae7913d266c08dd1ef78", "console": [], "id": "TqIu", "outputs": []}, {"code_hash": "5ac70cdb02d29c5dd0d2c492a3f3c6be", "console": [], "id": "DnEU", "outputs": []}], "metadata": {"marimo_version": "0.14.10"}, "version": "1"},
            "runtimeConfig": null,
        };
    </script>
  
<marimo-code hidden="">
    import%20marimo%0A%0A__generated_with%20%3D%20%220.14.10%22%0Aapp%20%3D%20marimo.App(width%3D%22medium%22)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20r%22%22%22%0A%20%20%20%20%3CStrong%3ECache%20Does%20Not%20Preserve%20Order%20of%20Insertion%3C%2Fstrong%3E%0A%0A%20%20%20%20One%20important%20thing%20to%20understand%20about%20the%20diskcache%20(and%20many%20other%20cache%20implementations)%20is%20that%20it%20is%20a%20key-value%20store%2C%20not%20a%20data%20structure%20that%20preserves%20the%20order%20of%20insertion%20or%20retrieval.%20When%20you%20iterate%20over%20the%20cache%20using%20methods%20like%20keys()%2C%20iterkeys()%2C%20or%20view().iterkeys()%2C%20the%20order%20of%20the%20keys%20returned%20is%20not%20necessarily%20the%20order%20in%20which%20they%20were%20inserted.%20The%20cache%20is%20essentially%20a%20hash-based%20structure%2C%20and%20the%20order%20of%20keys%20is%20typically%20not%20guaranteed.%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20import%20asyncio%0A%20%20%20%20import%20llm%0A%20%20%20%20import%20marimo%20as%20mo%0A%20%20%20%20import%20polars%20as%20pl%0A%20%20%20%20import%20matplotlib.pyplot%20as%20plt%0A%0A%20%20%20%20from%20dotenv%20import%20load_dotenv%0A%20%20%20%20from%20datasets%20import%20load_dataset%0A%20%20%20%20from%20mosync%20import%20async_map_with_retry%0A%20%20%20%20from%20diskcache%20import%20Cache%0A%20%20%20%20from%20sklearn.metrics%20import%20confusion_matrix%2C%20precision_score%0A%20%20%20%20load_dotenv(%22.env%22)%0A%20%20%20%20return%20(%0A%20%20%20%20%20%20%20%20Cache%2C%0A%20%20%20%20%20%20%20%20async_map_with_retry%2C%0A%20%20%20%20%20%20%20%20confusion_matrix%2C%0A%20%20%20%20%20%20%20%20llm%2C%0A%20%20%20%20%20%20%20%20load_dataset%2C%0A%20%20%20%20%20%20%20%20mo%2C%0A%20%20%20%20%20%20%20%20pl%2C%0A%20%20%20%20%20%20%20%20precision_score%2C%0A%20%20%20%20)%0A%0A%0A%40app.cell%0Adef%20_(llm)%3A%0A%20%20%20%20%23%20Show%20Async-Ready%20Models%0A%20%20%20%20for%20model%20in%20llm.get_async_models()%3A%0A%20%20%20%20%20%20%20%20print(model.model_id)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(load_dataset)%3A%0A%20%20%20%20%23%20Huggingface%20dataset%20about%20spam%3A%20%0A%20%20%20%20%23%20https%3A%2F%2Fhuggingface.co%2Fdatasets%2FDeysi%2Fspam-detection-dataset%0A%20%20%20%20df%20%3D%20load_dataset(%22Deysi%2Fspam-detection-dataset%22)%0A%20%20%20%20return%20(df%2C)%0A%0A%0A%40app.cell%0Adef%20_(df)%3A%0A%20%20%20%20df_train%20%3D%20df%5B%22train%22%5D.to_polars()%0A%20%20%20%20df_test%20%3D%20df%5B%22test%22%5D.to_polars()%0A%20%20%20%20return%20(df_test%2C)%0A%0A%0A%40app.cell%0Adef%20_(Cache%2C%20llm)%3A%0A%20%20%20%20cache%20%3D%20Cache(%22LLM_Prompt_Cache%22)%0A%0A%20%20%20%20models%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%22gpt-4%22%3A%20llm.get_async_model(%22gpt-4%22)%2C%0A%20%20%20%20%20%20%20%20%22gpt-4o%22%3A%20llm.get_async_model(%22gpt-4o%22)%2C%0A%20%20%20%20%20%20%20%20%22sonnet2024%22%3A%20llm.get_async_model(%22anthropic%2Fclaude-3-5-sonnet-20241022%22)%2C%0A%20%20%20%20%20%20%20%20%22haiku%22%3A%20llm.get_async_model(%22anthropic%2Fclaude-3-haiku-20240307%22)%0A%0A%20%20%20%20%7D%0A%20%20%20%20return%20cache%2C%20models%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20prompt%20%3D%20%22is%20this%20spam%20or%20ham%3F%20only%20reply%20with%20spam%20or%20ham%22%0A%20%20%20%20base_llm%20%3D%20%22sonnet2024%22%0A%20%20%20%20return%20base_llm%2C%20prompt%0A%0A%0A%40app.cell%0Adef%20_(base_llm%2C%20cache%2C%20models%2C%20prompt)%3A%0A%20%20%20%20async%20def%20classify(text%2C%20prompt%3Dprompt%2C%20model%3Dbase_llm)%3A%0A%20%20%20%20%20%20%20%20tup%20%3D%20(text%2C%20prompt%2C%20model)%0A%20%20%20%20%20%20%20%20if%20tup%20in%20cache%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23check%20if%20cached%20result%20is%20found%0A%20%20%20%20%20%20%20%20%20%20%20%20print(tup%20in%20cache)%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20cache%5Btup%5D%0A%20%20%20%20%20%20%20%20resp%20%3D%20await%20models%5Bmodel%5D.prompt(prompt%20%2B%20%22%5Cn%22%20%2B%20text).json()%0A%20%20%20%20%20%20%20%20cache%5Btup%5D%20%3D%20resp%0A%20%20%20%20%20%20%20%20return%20resp%0A%20%20%20%20return%20(classify%2C)%0A%0A%0A%40app.cell%0Aasync%20def%20_(classify)%3A%0A%20%20%20%20await%20classify(%22hello%20there%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Aasync%20def%20_(async_map_with_retry%2C%20classify%2C%20df_test)%3A%0A%20%20%20%20n_eval%20%3D%2050%0A%0A%20%20%20%20llm_results%20%3D%20await%20async_map_with_retry(%0A%20%20%20%20%20%20%20%20%5B_%5B%22text%22%5D%20for%20_%20in%20df_test.head(n_eval).to_dicts()%5D%2C%20%0A%20%20%20%20%20%20%20%20classify%2C%20%0A%20%20%20%20%20%20%20%20max_concurrency%3D3%2C%20%0A%20%20%20%20%20%20%20%20description%3D%22Running%20LLM%20experiments%22%0A%20%20%20%20)%0A%0A%20%20%20%20llm_results_list%20%3D%20%5B%5D%0A%20%20%20%20print(len(llm_results_list))%0A%20%20%20%20return%20llm_results%2C%20llm_results_list%0A%0A%0A%40app.cell%0Adef%20_(llm_results%2C%20llm_results_list)%3A%0A%20%20%20%20%23store%20the%20prompt%20as%20key%2C%20to%20be%20sure%2C%20that%20you%20have%20a%20contant%20match%20between%20predictions%20from%20cache%20and%20real%20labels%0A%20%20%20%20for%20k%2C%20result%20in%20enumerate(llm_results)%3A%0A%20%20%20%20%20%20%20%20llm_results_list.append((result.item%2C%20result.result%5B%22content%22%5D%5B0%5D%5B%22text%22%5D))%0A%0A%20%20%20%20print(len(llm_results_list))%0A%20%20%20%20llm_results_list%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(df_test%2C%20llm_results_list%2C%20pl)%3A%0A%20%20%20%20df_test_labels%20%3D%20(%0A%20%20%20%20%20%20%20%20df_test.head(50).with_columns(%0A%20%20%20%20%20%20%20%20%20%20%20%20trues%20%3D%20pl.when(pl.col(%22label%22).eq(%22not_spam%22)).then(pl.lit(%22ham%22)).otherwise(pl.lit(%22spam%22))%0A%20%20%20%20%20%20%20%20).select(%22text%22%2C%20%22trues%22)%0A%20%20%20%20)%0A%0A%20%20%20%20llm_frame%20%3D%20pl.DataFrame(llm_results_list%2C%20schema%3D%5B%22text%22%2C%20%22label_llm%22%5D%2C%20orient%3D%22row%22)%0A%0A%20%20%20%20df_equal%20%3D%20(%0A%20%20%20%20%20%20%20%20llm_frame%0A%20%20%20%20%20%20%20%20%20%20%20%20.join(df_test_labels%2C%20on%3D%22text%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20.with_columns(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20trues%20%3D%20pl.when(pl.col(%22trues%22).eq(%22ham%22)).then(1).otherwise(0)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20label_llm%20%3D%20pl.when(pl.col(%22label_llm%22).eq(%22ham%22)).then(1).otherwise(0)%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20)%0A%20%20%20%20return%20(df_equal%2C)%0A%0A%0A%40app.cell%0Adef%20_(confusion_matrix%2C%20df_equal)%3A%0A%20%20%20%20cm%20%3D%20confusion_matrix(y_true%3Ddf_equal%5B%22trues%22%5D%2C%20y_pred%3Ddf_equal%5B%22label_llm%22%5D)%0A%20%20%20%20cm%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(base_llm%2C%20df_equal%2C%20precision_score%2C%20prompt)%3A%0A%20%20%20%20print(%22model%3A%20%22%2C%20base_llm%2C%20%22prompt%3A%20%22%2C%20prompt%2C%20%22Precision%3A%22%2C%20precision_score(df_equal%5B%22trues%22%5D%2C%20df_equal%5B%22label_llm%22%5D%2C%20average%3D'weighted')%2C%20%22%25%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(base_llm%2C%20df_equal%2C%20precision_score%2C%20prompt)%3A%0A%20%20%20%20print(%22model%3A%22%2C%20base_llm%2C%20%22prompt%3A%20%22%2C%20prompt%2C%20%22Precision%3A%22%2C%20precision_score(df_equal%5B%22trues%22%5D%2C%20df_equal%5B%22label_llm%22%5D%2C%20average%3D'weighted')%2C%20%22%25%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(cache)%3A%0A%20%20%20%20cache.peekitem()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20%23import%20numpy%20as%20np%0A%20%20%20%20%23from%20sklearn.pipeline%20import%20make_pipeline%0A%20%20%20%20%23from%20sklearn.linear_model%20import%20LogisticRegression%0A%20%20%20%20%23from%20sklearn.feature_extraction.text%20import%20CountVectorizer%0A%20%20%20%20%23%0A%20%20%20%20%23df_valid%2C%20df_train%20%3D%20df.head(200)%2C%20df.tail(200)%0A%20%20%20%20%23text_valid%20%3D%20df_valid%5B%22text%22%5D.to_list()%0A%20%20%20%20%23text_train%20%3D%20df_train%5B%22text%22%5D.to_list()%0A%20%20%20%20%23y_valid%20%3D%20df_valid%5B%22label%22%5D.to_list()%0A%20%20%20%20%23y_train%20%3D%20df_train%5B%22label%22%5D.to_list()%0A%20%20%20%20%23%0A%20%20%20%20%23pipe%20%3D%20make_pipeline(CountVectorizer()%2C%20LogisticRegression())%0A%20%20%20%20%23%0A%20%20%20%20%23%23%20It's%20pretty%20dang%20accurate%0A%20%20%20%20%23preds%20%3D%20pipe.fit(text_train%2C%20y_train).predict(text_valid)%0A%20%20%20%20%23np.mean(preds%20%3D%3D%20np.array(y_valid))%0A%20%20%20%20return%0A%0A%0Aif%20__name__%20%3D%3D%20%22__main__%22%3A%0A%20%20%20%20app.run()%0A
</marimo-code>

<marimo-code-hash hidden="">76a21b6b16818d24200cc0b6b5b17112bec5e748f580b464db3c43d890f955a0</marimo-code-hash>
</body>
</html>
